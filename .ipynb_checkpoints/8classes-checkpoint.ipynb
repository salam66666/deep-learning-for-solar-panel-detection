{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ba95d1-d792-44fc-8486-acba441055d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 63, 63, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 63, 63, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 61, 61, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 61, 61, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 61, 61, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 61, 61, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 61, 61, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 61, 61, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 30, 30, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 30, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 30, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 30, 30, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 28, 28, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 13, 13, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 13, 13, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 13, 13, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 13, 13, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 13, 13, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 13, 13, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 13, 13, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 13, 13, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 13, 13, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 13, 13, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 13, 13, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 13, 13, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 13, 13, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 13, 13, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 13, 13, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 13, 13, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 13, 13, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 13, 13, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 13, 13, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 13, 13, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 13, 13, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 13, 13, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 13, 13, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 13, 13, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 13, 13, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 13, 13, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 13, 13, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 13, 13, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 13, 13, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 13, 13, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 13, 13, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 13, 13, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 13, 13, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 13, 13, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 13, 13, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 13, 13, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 13, 13, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 13, 13, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 13, 13, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 13, 13, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 13, 13, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 13, 13, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 13, 13, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 13, 13, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 13, 13, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 13, 13, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 13, 13, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 13, 13, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 13, 13, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 13, 13, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 13, 13, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 13, 13, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 13, 13, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 13, 13, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 13, 13, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 13, 13, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 13, 13, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 13, 13, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 13, 13, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 13, 13, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 13, 13, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 13, 13, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 13, 13, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 13, 13, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 13, 13, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 13, 13, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 13, 13, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 13, 13, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 13, 13, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 13, 13, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 13, 13, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 6, 6, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 6, 6, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 6, 6, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 6, 6, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 6, 6, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 6, 6, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 6, 6, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 6, 6, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 6, 6, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 6, 6, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 6, 6, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 6, 6, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 6, 6, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 6, 6, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 6, 6, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 6, 6, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 6, 6, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 6, 6, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 6, 6, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 6, 6, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 6, 6, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 6, 6, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 6, 6, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 6, 6, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 6, 6, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 6, 6, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 6, 6, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 6, 6, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 6, 6, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 6, 6, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 6, 6, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 6, 6, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 6, 6, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 6, 6, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 6, 6, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 6, 6, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 6, 6, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 6, 6, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 6, 6, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 6, 6, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 6, 6, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 6, 6, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 6, 6, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 6, 6, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 6, 6, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 6, 6, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 6, 6, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 6, 6, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 6, 6, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 6, 6, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 6, 6, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 6, 6, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 6, 6, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 6, 6, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 6, 6, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 6, 6, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 6, 6, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 6, 6, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 6, 6, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 6, 6, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 6, 6, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 6, 6, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 6, 6, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 6, 6, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 6, 6, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 6, 6, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 6, 6, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 6, 6, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 6, 6, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 6, 6, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 6, 6, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 6, 6, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 6, 6, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 6, 6, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 6, 6, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 6, 6, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 6, 6, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 6, 6, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 6, 6, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 6, 6, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 6, 6, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 6, 6, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 6, 6, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 6, 6, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 6, 6, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 6, 6, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 6, 6, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 6, 6, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 6, 6, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 6, 6, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 6, 6, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 6, 6, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 6, 6, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 6, 6, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 6, 6, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 6, 6, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 6, 6, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 6, 6, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 6, 6, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 6, 6, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 6, 6, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 6, 6, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 6, 6, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 6, 6, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 6, 6, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 6, 6, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 6, 6, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 6, 6, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 6, 6, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 6, 6, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 6, 6, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 6, 6, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 6, 6, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 6, 6, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 6, 6, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 6, 6, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 6, 6, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 6, 6, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 6, 6, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 6, 6, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 6, 6, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 6, 6, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 6, 6, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 6, 6, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 6, 6, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 6, 6, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 6, 6, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 6, 6, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 6, 6, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 6, 6, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 6, 6, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 6, 6, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2, 2, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 2, 2, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 2, 2, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 2, 2, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 2, 2, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 2, 2, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 2, 2, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 2, 2, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 2, 2, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 2, 2, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 2, 2, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 2, 2, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 2, 2, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 2, 2, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2, 2, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 2, 2, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 2, 2, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 2, 2, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 2, 2, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 2, 2, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 2, 2, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 2, 2, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 2, 2, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 2, 2, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2, 2, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 2, 2, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 2, 2, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 2, 2, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 2, 2, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 2, 2, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 2, 2, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 2, 2, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 2, 2, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 2, 2, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 2, 2, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 2, 2, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 2, 2, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 2, 2, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 2, 2, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 2, 2, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 2, 2, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 2, 2, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 2, 2, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 2, 2, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 2, 2, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 2, 2, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2, 2, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 2, 2, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 2, 2, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 2, 2, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4, 2048)      0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 4, 128)       1114624     reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 4, 128)       256         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 4, 128)       131968      layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 256)       0           layer_normalization[0][0]        \n",
      "                                                                 multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          65792       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            2056        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,117,480\n",
      "Trainable params: 18,669,448\n",
      "Non-trainable params: 4,448,032\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Slamabart\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Slamabart\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Slamabart\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\input_spec.py:266 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 128, 128, 3), found shape=(None, 78, 129, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 175\u001b[0m\n\u001b[0;32m    159\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    160\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[0;32m    161\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[0;32m    172\u001b[0m ]\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m    184\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(model\u001b[38;5;241m.\u001b[39mpredict(test_dataset), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:759\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    763\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:3066\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3066\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:3463\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3460\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3463\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3293\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3295\u001b[0m ]\n\u001b[0;32m   3296\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3297\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3306\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3310\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3311\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3312\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3313\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3314\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3315\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1007\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1012\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:668\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    665\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 668\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    669\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:994\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    993\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    995\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Slamabart\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Slamabart\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Slamabart\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    E:\\Anaconda\\envs\\TF2\\lib\\site-packages\\keras\\engine\\input_spec.py:266 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 128, 128, 3), found shape=(None, 78, 129, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# \n",
    "ORIGINAL_HEIGHT = 24    # \n",
    "ORIGINAL_WIDTH = 40\n",
    "TARGET_SIZE = 128       # \n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 8\n",
    "EPOCHS = 50             # \n",
    "SEED = 42\n",
    "\n",
    "# \n",
    "DATASET_DIR = r'E:\\CDUT\\English\\7 Term\\Project\\model\\archive\\8classes'\n",
    "\n",
    "# \n",
    "scale = min(TARGET_SIZE/ORIGINAL_HEIGHT, TARGET_SIZE/ORIGINAL_WIDTH)\n",
    "new_h = int(ORIGINAL_HEIGHT * scale)\n",
    "new_w = int(ORIGINAL_WIDTH * scale)\n",
    "\n",
    "# \n",
    "def prepare_datasets(root_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(root_dir))\n",
    "    \n",
    "    for label_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_paths.append(os.path.join(class_dir, filename))\n",
    "                labels.append(label_idx)\n",
    "    \n",
    "    return image_paths, np.array(labels), class_names\n",
    "\n",
    "# \n",
    "def preprocess_image(image, augment=False):\n",
    "    # \n",
    "    image = tf.image.resize(\n",
    "        image, [new_h, new_w],\n",
    "        method=tf.image.ResizeMethod.BICUBIC\n",
    "    )\n",
    "    image = tf.image.pad_to_bounding_box(\n",
    "        image, \n",
    "        offset_height=(TARGET_SIZE-new_h)//2,\n",
    "        offset_width=(TARGET_SIZE-new_w)//2,\n",
    "        target_height=TARGET_SIZE,\n",
    "        target_width=TARGET_SIZE\n",
    "    )\n",
    "    \n",
    "    # \n",
    "    if augment:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_brightness(image, 0.15)\n",
    "        image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    \n",
    "    return image/255.0\n",
    "\n",
    "def create_dataset(image_paths, labels, augment=False):\n",
    "    def parse_function(path, label):\n",
    "        image = tf.io.decode_jpeg(tf.io.read_file(path), channels=3)\n",
    "        return preprocess_image(image, augment), label\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# \n",
    "def build_optimized_model():\n",
    "    # \n",
    "    base_model = InceptionV3(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(TARGET_SIZE, TARGET_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # \n",
    "    for layer in base_model.layers[:150]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[150:]:\n",
    "        if isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "\n",
    "    # \n",
    "    x = base_model.output\n",
    "    h, w = base_model.output.shape[1], base_model.output.shape[2]\n",
    "    x = layers.Reshape((h * w, 2048))(x)\n",
    "    \n",
    "    # \n",
    "    x = layers.LSTM(128, return_sequences=True, dropout=0.3)(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    \n",
    "    # \n",
    "    attn = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "    x = layers.Concatenate()([x, attn])\n",
    "    \n",
    "    # \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(256, activation='relu', \n",
    "                    kernel_regularizer=regularizers.l1_l2(1e-5, 1e-4))(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    \n",
    "    return models.Model(base_model.input, outputs)\n",
    "\n",
    "# \n",
    "if __name__ == \"__main__\":\n",
    "    # \n",
    "    image_paths, labels, class_names = prepare_datasets(DATASET_DIR)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        image_paths, labels, test_size=0.2, stratify=labels, random_state=SEED)\n",
    "    \n",
    "    # \n",
    "    train_dataset = create_dataset(X_train, y_train, augment=True)\n",
    "    test_dataset = create_dataset(X_test, y_test)\n",
    "    \n",
    "    # \n",
    "    model = build_optimized_model()\n",
    "    optimizer = optimizers.Adam(\n",
    "        learning_rate=1e-4,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07,\n",
    "        amsgrad=True\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "    # \n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    # \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=12,\n",
    "            restore_best_weights=True,\n",
    "            mode='max'\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # \n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=test_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # \n",
    "    y_pred = np.argmax(model.predict(test_dataset), axis=1)\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "    \n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d487ce79-bafc-412f-86f4-4eaa58c5879a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_preprocessing(image_path):\n",
    "    # \n",
    "    raw_image = tf.io.read_file(image_path)\n",
    "    raw_image = tf.image.decode_jpeg(raw_image, channels=3)\n",
    "    \n",
    "    # \n",
    "    processed_image = preprocess_image(raw_image, augment=False)\n",
    "    \n",
    "    # numpy\n",
    "    raw_img_np = raw_image.numpy().astype('uint8')\n",
    "    proc_img_np = processed_image.numpy().astype('uint8')\n",
    "    \n",
    "    # \n",
    "    plt.figure(figsize=(10,5))\n",
    "    \n",
    "    # \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(raw_img_np)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(proc_img_np)\n",
    "    plt.title('Processed Image (128128)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# \n",
    "sample_path = image_paths[0]  # \n",
    "visualize_preprocessing(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c092e-929e-4ed8-95c7-a1b86241c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(y_train, y_test, class_names):\n",
    "    # \n",
    "    train_counts = np.bincount(y_train, minlength=NUM_CLASSES)\n",
    "    test_counts = np.bincount(y_test, minlength=NUM_CLASSES)\n",
    "    \n",
    "    # \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # \n",
    "    bar_width = 0.35\n",
    "    index = np.arange(NUM_CLASSES)\n",
    "    \n",
    "    # \n",
    "    train_color = '#1f77b4'  # \n",
    "    test_color = '#ff7f0e'   # \n",
    "    \n",
    "    # \n",
    "    bars_train = plt.bar(index - bar_width/2, train_counts, bar_width,\n",
    "                        color=train_color, label='train')\n",
    "    bars_test = plt.bar(index + bar_width/2, test_counts, bar_width,\n",
    "                       color=test_color, label='val')\n",
    "    \n",
    "    # \n",
    "    def add_labels(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                     f'{height}',\n",
    "                     ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    add_labels(bars_train)\n",
    "    add_labels(bars_test)\n",
    "    \n",
    "    # \n",
    "    plt.title(f'{NUM_CLASSES} classes', fontsize=14, pad=20)\n",
    "    plt.xlabel('defect type', fontsize=12)\n",
    "    plt.ylabel('number of sample', fontsize=12)\n",
    "    plt.xticks(index, class_names, rotation=45, ha='right', fontsize=10)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # \n",
    "    plt.show()\n",
    "\n",
    "# \n",
    "plot_class_distribution(\n",
    "    y_train=y_train,  # train_test_split\n",
    "    y_test=y_test,    # \n",
    "    class_names=class_names[:NUM_CLASSES]  # NUM_CLASSES\n",
    ")\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0153d-096c-43a6-9e5a-d4a2e169e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# \n",
    "y_pred_probs = model.predict(test_dataset)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# \n",
    "y_true = np.concatenate([y.numpy() for _, y in test_dataset], axis=0)\n",
    "\n",
    "# \n",
    "print(\"\\n\")\n",
    "print(\":\", y_pred[:10])\n",
    "print(\":\", y_true[:10])\n",
    "\n",
    "# \n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, \n",
    "            yticklabels=class_names)\n",
    "plt.xlabel(\"Pre label\", fontsize=12)\n",
    "plt.ylabel(\"real label\", fontsize=12)\n",
    "plt.title(\"confusion matrix\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# ROCOvR\n",
    "n_classes = len(class_names)\n",
    "y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "\n",
    "# ROC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# ROC\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(all_fpr, mean_tpr, color='darkorange',\n",
    "         label=f' ROC (AUC = {auc(all_fpr, mean_tpr):.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# \n",
    "print(\"\\n\")\n",
    "print(f\": {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\": {precision_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\": {recall_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"F1: {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "\n",
    "# \n",
    "print(\"\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd423f-3903-4f10-8c1d-65cde355d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb092f5-157a-4eef-bd78-080bb771e353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (openCV)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
